# All available Hugo versions are listed here: https://gitlab.com/pages/hugo/container_registry
image: registry.gitlab.com/pages/hugo/hugo_extended:latest
# image: monachus/hugo

variables:
  GIT_SUBMODULE_STRATEGY: recursive

before_script:
  - apk update
  - apk add git
  - apk add nodejs
  - apk add npm
  - apk add curl
  - npm install postcss postcss-cli autoprefixer cssnano @fullhuman/postcss-purgecss

test:
  stage: test
  script:
  - hugo --destination ./test
  artifacts:
    paths:
    - test
    - resources
    expire_in: 1 week
  except:
  - master


#
# https://webd97.de/post/gitlab-pages-compression/
# BeginQuote
#   To enable compression, we need to create static compressed files.
#   Since we are working with static files, it is no problem at all to provide compressed variants of these files.
#   We just need to call gzip for each file.
#   For this website, I implemented this by calling gzip -k -6 $(find public -type f) after the successful Hugo build.
#   The -k flags keeps the input files, 9 is the compression level (1-9).
#   Unfortunately, the -r (recursive) flag is not supported by the base image, so I had to use a workaround here: find public -type f lists all files in the public directory (created by Hugo) recursively, which are then passed to gzip.
# EndQuote
#
pages:
  stage: deploy
  script:
  - hugo --minify # run hugo with minify option to minify all the HTML
  - gzip -k -9 $(find public -type f) # use gzip for compression
  - curl "https://www.google.com/ping?sitemap=https://softorage.com/sitemap.xml" # ping Google to scan sitemap
  - curl "https://www.google.com/ping?sitemap=https://softorage.com/index.xml" # ping Google to scan sitemap
  artifacts:
    paths:
    - public
    - resources # since artifacts are considered in calculating size occupied, it is not taken
    expire_in: 1 week
  only:
  - master
